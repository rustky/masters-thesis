{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc025cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507110d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 6.5, 7. , 7.5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponents = np.arange(2,8,.5)\n",
    "exponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abd3969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 316, 1000, 3162, 10000, 31622, 100000, 316228, 1000000, 3162278, 10000000, 31622777]\n"
     ]
    }
   ],
   "source": [
    "num_data_points = []\n",
    "data_list = []\n",
    "for i in range(len(exponents)):\n",
    "    num_data_points.append(round(10**exponents[i]))\n",
    "    if num_data_points[i] == 31623:\n",
    "        num_data_points[i] = num_data_points[i] - 1\n",
    "    tensor = torch.from_numpy(np.random.standard_normal(num_data_points[i]))\n",
    "    data_list.append(tensor.type(torch.DoubleTensor))\n",
    "print(num_data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f140ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "316\n",
      "1000\n",
      "3162\n",
      "10000\n",
      "31622\n",
      "100000\n",
      "316228\n",
      "1000000\n",
      "3162278\n",
      "10000000\n",
      "31622776\n"
     ]
    }
   ],
   "source": [
    "label_list = []\n",
    "for j in num_data_points:\n",
    "    temp = torch.from_numpy(np.repeat([0,1], j/2))\n",
    "    print(len(temp))\n",
    "    label_list.append(temp.type(torch.DoubleTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8872ee43",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_exp = np.arange(-5,0.5,0.5)\n",
    "time_exp\n",
    "time_limits = []\n",
    "for k in time_exp:\n",
    "    time_limits.append(10**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79312a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from square_loss import square_loss\n",
    "from squared_hinge_loss import squared_hinge_loss\n",
    "from naive_square_loss import naive_square_loss\n",
    "from naive_square_hinge_loss import naive_square_hinge_loss\n",
    "from torch.nn import BCEWithLogitsLoss as logisitic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f16a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss = logisitic_loss()\n",
    "loss_dict ={\n",
    "    \"naive_square\": naive_square_loss,\n",
    "    \"naive_square_hinge\": naive_square_hinge_loss,\n",
    "    \"square_loss\":square_loss,\n",
    "    \"squared_hinge_loss\": squared_hinge_loss,\n",
    "    \"logistic_loss\": log_loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06a7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38888e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_square\n",
      "1e-05\n",
      "time too big\n",
      "3.1622776601683795e-05\n",
      "time too big\n",
      "0.0001\n",
      "time too big\n",
      "0.00031622776601683794\n",
      "time too big\n",
      "0.001\n",
      "time too big\n",
      "0.0031622776601683794\n",
      "time too big\n",
      "0.01\n",
      "time too big\n",
      "0.03162277660168379\n",
      "time too big\n",
      "0.1\n",
      "time too big\n",
      "0.31622776601683794\n",
      "time too big\n",
      "1.0\n",
      "time too big\n",
      "naive_square_hinge\n",
      "1e-05\n",
      "time too big\n",
      "3.1622776601683795e-05\n",
      "time too big\n",
      "0.0001\n",
      "time too big\n",
      "0.00031622776601683794\n",
      "time too big\n",
      "0.001\n",
      "time too big\n",
      "0.0031622776601683794\n",
      "time too big\n",
      "0.01\n",
      "time too big\n",
      "0.03162277660168379\n",
      "time too big\n",
      "0.1\n",
      "time too big\n",
      "0.31622776601683794\n",
      "time too big\n",
      "1.0\n",
      "time too big\n",
      "square_loss\n",
      "1e-05\n",
      "time too big\n",
      "3.1622776601683795e-05\n",
      "time too big\n",
      "0.0001\n",
      "time too big\n",
      "0.00031622776601683794\n",
      "time too big\n",
      "0.001\n",
      "time too big\n",
      "0.0031622776601683794\n",
      "time too big\n",
      "0.01\n",
      "time too big\n",
      "0.03162277660168379\n",
      "time too big\n",
      "0.1\n",
      "time too big\n",
      "0.31622776601683794\n",
      "time too big\n",
      "1.0\n",
      "squared_hinge_loss\n",
      "1e-05\n",
      "time too big\n",
      "3.1622776601683795e-05\n",
      "time too big\n",
      "0.0001\n",
      "time too big\n",
      "0.00031622776601683794\n",
      "time too big\n",
      "0.001\n",
      "time too big\n",
      "0.0031622776601683794\n",
      "time too big\n",
      "0.01\n",
      "time too big\n",
      "0.03162277660168379\n",
      "time too big\n",
      "0.1\n",
      "time too big\n",
      "0.31622776601683794\n",
      "time too big\n",
      "1.0\n",
      "time too big\n",
      "logistic_loss\n",
      "1e-05\n",
      "time too big\n",
      "3.1622776601683795e-05\n",
      "time too big\n",
      "0.0001\n",
      "time too big\n",
      "0.00031622776601683794\n",
      "time too big\n",
      "0.001\n",
      "time too big\n",
      "0.0031622776601683794\n",
      "time too big\n",
      "0.01\n",
      "time too big\n",
      "0.03162277660168379\n",
      "time too big\n",
      "0.1\n",
      "time too big\n",
      "0.31622776601683794\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([31622776])) must be the same as input size (torch.Size([31622777]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_673164/3367178327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mtime_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_vec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([31622776])) must be the same as input size (torch.Size([31622777]))"
     ]
    }
   ],
   "source": [
    "times_dict_list = []\n",
    "for loss_name, loss_fun in loss_dict.items():\n",
    "    print(loss_name)\n",
    "    for times in time_limits:\n",
    "        print(times)\n",
    "        for x in range(len(data_list)):\n",
    "#             print(num_data_points[x])\n",
    "            time_vec = np.zeros(10)\n",
    "            for iter in range(10):\n",
    "#                 print(iter)\n",
    "                start_time = time.time()\n",
    "                if loss_name not in [\"logistic_loss\"]:\n",
    "                    loss = loss_fun(data_list[x], label_list[x], 1)\n",
    "                else:\n",
    "                    loss = loss_fun(data_list[x], label_list[x])\n",
    "                time_vec[iter] = time.time() - start_time\n",
    "            if (np.median(time_vec) > times):\n",
    "                print(\"time too big\")\n",
    "                max_dict = {\n",
    "                    \"loss_name\": loss_name,\n",
    "                    \"max_time\": np.max(time_vec),\n",
    "                    \"min_time\": np.min(time_vec),\n",
    "                    \"median_time\": np.median(time_vec),\n",
    "                    \"data_size\": num_data_points[x],\n",
    "                    \"time_limit\":times\n",
    "                }\n",
    "                times_dict_list.append(pd.DataFrame(max_dict,index=[0]))\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2335f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dt = pd.concat(times_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a2b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb1b0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dt.to_csv(\"timing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a8d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
